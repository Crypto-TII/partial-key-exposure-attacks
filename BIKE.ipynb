{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2, inf\n",
    "from math import comb as binom\n",
    "from scipy.stats import bernoulli\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#insall from https://github.com/Crypto-TII/syndrome_decoding_estimator\n",
    "from sd_estimator.estimator import stern_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def less_than_x(n,x,p):\n",
    "    return sum(binom(n,i)*(1-p)^(n-i)*p^i for i in range(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def less_than_x_asym(n,x,p1,p2):\n",
    "    s=0\n",
    "    for i in range(x):\n",
    "        ws_i= binom(n//2,i)*(1-p1)^(n//2-i)*p1^i \n",
    "        ws_j= sum(binom(n//2,o)*(1-p2)^(n//2-o)*p2^o for o in range(x-i))\n",
    "        s+=ws_i*ws_j\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-furniture",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute list of binary vectors of length n and weight k\n",
    "def GospersHack(k,n):\n",
    "    L_vecs=[]\n",
    "    setb = (1 << k) - 1;\n",
    "    limit = (1 << n);\n",
    "    while setb < limit:\n",
    "        \n",
    "        L_vecs.append(setb)\n",
    "        c = setb & - setb;\n",
    "        r = setb + c;\n",
    "        setb = int(((r ^^ setb) >> 2) / c) | int(r);\n",
    "    return L_vecs\n",
    "\n",
    "#compute all binary vectors of length n with weight at most k\n",
    "def all_gosps(k,n):\n",
    "    L=[0]\n",
    "    for i in range(1,k+1):\n",
    "        L+=GospersHack(i,n)\n",
    "    return L\n",
    "\n",
    "#Hamming weight\n",
    "def weight(x):\n",
    "    w=0\n",
    "    while(x):\n",
    "        x&=(x-1)\n",
    "        w+=1\n",
    "    return w\n",
    "\n",
    "#plots two lists Ls=[[xi,yi]], Ll=[[vi,wi]]\n",
    "def plot_lists(Ls,Ll):\n",
    "    Lp_short_x=[i[0] for i in Ls]\n",
    "    Lp_short_y=[i[1] for i in Ls]\n",
    "    Lp_long_x=[i[0] for i in Ll]\n",
    "    Lp_long_y=[i[1] for i in Ll]\n",
    "    plt.scatter(Lp_short_x,Lp_short_y)\n",
    "    plt.scatter(Lp_long_x,Lp_long_y)\n",
    "    \n",
    "def avg_lists(L):\n",
    "    Lpx=[i[0] for i in L]\n",
    "    Lpy=[i[1] for i in L]\n",
    "\n",
    "    avg=[]\n",
    "    sumi=count=0\n",
    "    for i in range(len(Lpx)):\n",
    "        sumi+=Lpy[i]\n",
    "        count+=1\n",
    "        if i==len(Lpx)-1 or Lpx[i]!=Lpx[i+1]:\n",
    "            avg.append([Lpx[i],sumi/count])\n",
    "            count=sumi=0\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-norwegian",
   "metadata": {},
   "source": [
    "### Functions for error experiments in standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates erroneous key in the standard format\n",
    "def gen_cb_instance_long_rep(k,w,p1,p2):\n",
    "    bits=int(ceil(log2(k)))\n",
    "    x=bernoulli(p1)\n",
    "    y=bernoulli(p2)\n",
    "    \n",
    "    L=zero_vector(GF(2),2*k)\n",
    "    k2_range=[i for i in range(2*k)]\n",
    "    shuffle(k2_range)\n",
    "    for i in range(w):\n",
    "        L[k2_range[i]]=1\n",
    "    \n",
    "    \n",
    "    L_f=zero_vector(GF(2),2*k)\n",
    "    for i in range(2*k):\n",
    "        L_f[i]=L[i]\n",
    "        if L_f[i]:\n",
    "            L_f[i]+=x.rvs(1)[0]\n",
    "        else:\n",
    "            L_f[i]+=y.rvs(1)[0]\n",
    "            \n",
    "    return L,L_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs the number of missing one entries in sf which are present in s\n",
    "def missing_ones_long_rep(s,sf):\n",
    "    count=0\n",
    "    for i in range(len(s)):\n",
    "        if s[i] and not(sf[i]):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "#iterations of prange ISD on code with n=2*k with c candidates fixed in the information set \n",
    "def comp(k,c,wp):\n",
    "    return log2(binom(2*k-c,wp)/binom(k-c,wp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected number of iterations of Prange ISD to recover BIKE secret key from erroneous key with error probabilities p1 and p2\n",
    "def complexity_long_rep(k,w,p1,p2):\n",
    "    s,sf=gen_cb_instance_long_rep(k,w,p1,p2)\n",
    "    wp,c=missing_ones_long_rep(s,sf),sf.hamming_weight()\n",
    "    return comp(k,c,wp)#,c,wp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-commons",
   "metadata": {},
   "source": [
    "### Functions for Compact Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate erroneous BIKE secret key in compact format\n",
    "def gen_cb_instance(k,w,p1,p2):\n",
    "    \n",
    "    bits=int(ceil(log2(k)))\n",
    "    x=bernoulli(p1)\n",
    "    y=bernoulli(p2)\n",
    "    \n",
    "    L=[randint(0,k) for _ in range(w)]\n",
    "    \n",
    "    L_f=[]\n",
    "    for i in L:\n",
    "        val=i\n",
    "        for j in range(bits):\n",
    "            mask=1<<j\n",
    "            if val & mask:\n",
    "                val^^=(x.rvs(1)[0]<<j)\n",
    "            else:\n",
    "                val^^=(y.rvs(1)[0]<<j)\n",
    "        L_f.append(val)\n",
    "    return L,L_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number iterations of Prange-ISD with two blocks of different weight\n",
    "def time_2_blocks(k,c,w,wp):\n",
    "    t=[inf]\n",
    "    for p in range(w-wp,min(c+1,k-wp-1)):\n",
    "        tmp=log2(binom(c,w-wp))+log2(binom(2*k-c,wp))-log2(binom(p,w-wp))-log2(binom(k-p,wp))\n",
    "        if tmp<t[0]:\n",
    "            t=[tmp,p]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number iterations of Prange-ISD with two blocks of different weight\n",
    "def time_2_blocks(k,c,w,wp):\n",
    "    t=[inf]\n",
    "    for p in range(w-wp,min(c+1,k-wp-1)):\n",
    "        tmp=log2(binom(c,w-wp))+log2(binom(2*k-c,wp))-log2(binom(p,w-wp))-log2(binom(k-p,wp))\n",
    "        if tmp<t[0]:\n",
    "            t=[tmp,p]\n",
    "    return t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of candidates L based on erroneous key indices Lf. \n",
    "#Consider all x for L, with x = y + e, where y in L and weight(e)<maxw. \n",
    "#Include only those x in L for which there exists an y in Lf such that it holds that Pr[x in L | y in Lf]>threshold.\n",
    "def gen_candidates(maxw,threshold,bits,L_f,k):\n",
    "    s=0\n",
    "    colls=0\n",
    "    Lvecs=all_gosps(maxw,bits)\n",
    "    L_candidates=set([])\n",
    "    mask=(1<<bits)-1\n",
    "    \n",
    "    for l in range(len(L_f)):\n",
    "        len_bef=len(L_candidates)\n",
    "        i=L_f[l]\n",
    "        for j in Lvecs:\n",
    "            n00=n01=n10=n11=0\n",
    "            j^^=i\n",
    "            n11= weight(j&i)\n",
    "            n00= weight((j^^mask)& (i^^mask))\n",
    "            n10=weight(j & (i^^mask))\n",
    "            n01=weight((j^^mask) & i)\n",
    "\n",
    "            score=(1-p2)^n00*p2^n01*p1^n10*(1-p1)^n11\n",
    "            if score>threshold and j<k:\n",
    "                if l> len(L_f)/2:\n",
    "                    if j+k in L_candidates:\n",
    "                        colls+=1\n",
    "                    L_candidates.add(j+k)\n",
    "                else:\n",
    "                    if j in L_candidates:\n",
    "                        colls+=1\n",
    "                    L_candidates.add(j)\n",
    "    return L_candidates\n",
    "\n",
    "#determine number of missing one-indices of the BIKE secret key (L) in the list of candidates Lcand\n",
    "def missing(Lcand,L,k):\n",
    "    miss=0\n",
    "    for i in range(len(L)):\n",
    "        z= L[i] if i<len(L)/2 else L[i]+k\n",
    "        if z not in Lcand:\n",
    "            miss+=1\n",
    "    return miss\n",
    "\n",
    "#recursive function to determine the expected size of the union of (i+1) random sets of size L0 containing elements from {1,...,k}\n",
    "def f_L(i,k,L0):\n",
    "    if i==0:\n",
    "        return L0\n",
    "    return (f_L(i-1,k,L0)*(1-L0/k)+L0).n()\n",
    "\n",
    "#approximation of the threshold required to obtain a list of candidates of size about k*0.95 from gen_candidates\n",
    "def find_probability(k,w,L_f,p1,p2):\n",
    "    bits=int(ceil(log2(k)))\n",
    "    avg_size=inf\n",
    "    prob=0.00001\n",
    "    factor=k/(1<<bits).n()\n",
    "    while(avg_size>k*0.95):\n",
    "        prob+=0.00001\n",
    "        avg_weight=int(ceil((sum(weight(L_f[i]) for i in range(len(L_f)))/len(L_f)).n()))\n",
    "\n",
    "        for i in range(bits-avg_weight):\n",
    "            ws=p1^i*(1-p1)^(bits-avg_weight-i)\n",
    "            if ws <prob or i==bits-avg_weight-1:\n",
    "                wi=i\n",
    "                break\n",
    "\n",
    "        avg_elements=sum(binom(bits-avg_weight,i) for i in range(min(wi,6)))\n",
    "        avg_size=f_L(w//2-1,k,int(factor*avg_elements))*2\n",
    "    return prob,wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine complexity for key recovery in compact format for given (or generated) erroneous BIKE key\n",
    "def complexity_short_rep(k,w,p1,p2,threshold,keys=0):\n",
    "    if keys==0:\n",
    "        L,L_f=gen_cb_instance(k,w,p1,p2)\n",
    "    else:\n",
    "        L,L_f=keys\n",
    "    bits=int(ceil(log2(k)))\n",
    "    Lcand=gen_candidates(maxw,threshold,bits,L_f,k)\n",
    "    c,wp=(len(Lcand),missing(Lcand,L,k))\n",
    "    tmp=time_2_blocks(k,c,w,wp)\n",
    "    return tmp,c,wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates erroneous BIKE compact key and finds threshold leading to best attack complexity\n",
    "def complexity_short_rep_increase_prob(k,w,p1,p2,prob_start=0, inc=0):\n",
    "    L,L_f=gen_cb_instance(k,w,p1,p2)\n",
    "    iprob,maxw=find_probability(k,w,L_f,p1,p2)\n",
    "    prob=max(iprob-0.0005,iprob/21)\n",
    "    if p1>0.2:\n",
    "        prob /=16\n",
    "    if prob_start!=0:\n",
    "        prob=prob_start\n",
    "    t=inf\n",
    "    vals=[]\n",
    "    first=1\n",
    "    eqc=0\n",
    "    while(1):\n",
    "        tmp,c,wp=complexity_short_rep(k,w,p1,p2,prob,keys=[L,L_f])\n",
    "        #print(tmp,c,wp,prob)\n",
    "        if tmp<t:\n",
    "            t=tmp\n",
    "            vals=[c,wp,prob]\n",
    "        elif tmp==t:\n",
    "            eqc+=1\n",
    "        elif c<k and tmp-t>1:\n",
    "            break\n",
    "        if inc==0:\n",
    "            prob+=0.00001\n",
    "        else:\n",
    "            prob+=inc\n",
    "        if (eqc>3 or t<0.001) and c<k:\n",
    "            break\n",
    "        \n",
    "    return t#,vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-shell",
   "metadata": {},
   "source": [
    "### Experiment on complexity for symmetric error probabilities\n",
    "Note that the error experiments on the compact format are very slow, due to the candidate generation, better run them overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose parameter set to use\n",
    "k,w=(12323, 142)\n",
    "#k,w=(40973, 274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used approximation of logaithm of polynomial factors of Prange's algorithm\n",
    "poly_factors =2.8*log2(k)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform experiment for symmetric error, compute 10 data points per format (compact / standard)\n",
    "L_short_sym=[]\n",
    "L_long_sym=[]\n",
    "\n",
    "p1=0.025\n",
    "while p1<0.301:\n",
    "    pstart=0\n",
    "    for i in range(10):\n",
    "        tmp_short=complexity_short_rep_increase_prob(k,w,p1,p1,prob_start=pstart)\n",
    "        tmp_long =complexity_long_rep(k,w,p1,p1)\n",
    "        L_short_sym.append([p1,tmp_short+poly_factors])\n",
    "        L_long_sym.append([p1,tmp_long+poly_factors])\n",
    "    print(p1,tmp_long)\n",
    "    p1+=0.025\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lists(L_short_sym,L_long_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B=avg_lists(L_short_sym),avg_lists(L_long_sym)\n",
    "plot_lists(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-broadcasting",
   "metadata": {},
   "source": [
    "### Experiment on complexity for asymmetric error probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform experiment for symmetric error, compute 10 data points per format (compact / standard)\n",
    "L_short_asym=[]\n",
    "L_long_asym=[]\n",
    "\n",
    "p1=0.025\n",
    "while p1<0.301:\n",
    "    pstart=0\n",
    "    for i in range(1):\n",
    "        tmp_short=complexity_short_rep_increase_prob(k,w,p1,0.001,prob_start=pstart)\n",
    "        tmp_long =complexity_long_rep(k,w,p1,0.001)\n",
    "        L_short_asym.append([p1,tmp_short+poly_factors])\n",
    "        L_long_asym.append([p1,tmp_long+poly_factors])\n",
    "    print(p1,tmp_long)\n",
    "    p1+=0.025\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lists(L_short_asym,L_long_asym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B=avg_lists(L_short_sym),avg_lists(L_long_sym)\n",
    "plot_lists(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-accuracy",
   "metadata": {},
   "source": [
    "### Erasure experiments compact representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate partially erased BIKE private key in compact format\n",
    "def simulate_erasure(k,w,p):\n",
    "    x=bernoulli(p)\n",
    "    bits=int(ceil(log2(k)))\n",
    "    Lerasures=[]\n",
    "    for i in range(w):\n",
    "        cur=[]\n",
    "        for j in range(bits):\n",
    "            if x.rvs(1)[0]:\n",
    "                cur.append(j)\n",
    "        Lerasures.append(cur)\n",
    "    return Lerasures\n",
    "\n",
    "#Genrate list of all candidates, based on known key coordinates (L) and erasure positions (Lerasures)\n",
    "def gen_erasure_candidates(L,Lerasures,k):\n",
    "    mask=(1<<int(ceil(log2(k))))-1\n",
    "    cand=set([])\n",
    "    c=0\n",
    "    for i in Lerasures:\n",
    "        key_index=L[c]\n",
    "        for j in range(2**len(i)):\n",
    "            for o in range(len(i)):\n",
    "                current_bit=1<<i[o]\n",
    "                neg = current_bit^^mask\n",
    "                key_index&=neg\n",
    "                if (j>>o)&1:\n",
    "                    key_index ^^= current_bit\n",
    "            if len(i)!=0:\n",
    "                if c<w/2:\n",
    "                    cand.add(key_index)\n",
    "                else:\n",
    "                    cand.add(key_index+k)\n",
    "        c+=1\n",
    "    return cand\n",
    "\n",
    "#bit complexity to recover partially erased BIKE secret key\n",
    "def complexity_erasure(cand,L,Lerasures,k,w):\n",
    "    np=len(cand)\n",
    "    wp=w-sum(1 for i in Lerasures if len(i)==0)\n",
    "    if np<k:\n",
    "        return log2(k)*2.8\n",
    "    return stern_complexity(np,np-k,wp)[\"time\"]+log2(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcomplexity=[]\n",
    "p=0.4\n",
    "while p<=0.54:\n",
    "    for _ in range(100):\n",
    "        Lerasures=simulate_erasure(k,w,p)\n",
    "        L,Lf=gen_cb_instance(k,w,p,p)\n",
    "        cand=gen_erasure_candidates(L,Lerasures,k)\n",
    "        Lcomplexity.append([p,complexity_erasure(cand,L,Lerasures,k,w)])\n",
    "    print(p)\n",
    "    p+=0.005\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcomplexity_short_1= [i for i in Lcomplexity if i[1]!=inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcomplexity_short_avg=avg_lists(Lcomplexity_short_1)\n",
    "plot_lists(Lcomplexity_short_avg,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-employee",
   "metadata": {},
   "source": [
    "### Erasure experiments standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate partially-erased BIKE key in the standard format\n",
    "def simulate_erasure_long_rep(k,w,p):\n",
    "    x=bernoulli(p)\n",
    "    bits=int(ceil(log2(k)))\n",
    "    Lerasures=[]\n",
    "    for i in range(2*k):\n",
    "        if x.rvs(1)[0]:\n",
    "            Lerasures.append(i)\n",
    "    return Lerasures\n",
    "\n",
    "#Complexity to recover partially-erased BIKE key in standard foramt\n",
    "def complexity_erasure_long(L,Lerasures,k,w):\n",
    "    np=len(Lerasures)\n",
    "    wp=sum(1 for i in Lerasures if L[i]==1)\n",
    "    if np<k:\n",
    "        return 2.8*log2(k)\n",
    "    return stern_complexity(np,np-k,wp)[\"time\"]+log2(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate 10 datapoints for bit complexity of recovery of partially erased BIKE key in standard format\n",
    "L,Lf=gen_cb_instance_long_rep(k,w,p,p)\n",
    "Lcomplexity_std=[]\n",
    "p=0.35\n",
    "while p<=1:\n",
    "    for _ in range(10):\n",
    "        Lerasures=simulate_erasure_long_rep(k,w,p)\n",
    "        Lcomplexity_std.append([p,complexity_erasure_long(L,Lerasures,k,w)])\n",
    "    print(p)\n",
    "    p+=0.01\n",
    "    \n",
    "list_plot(Lcomplexity_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcomplexity_std=[i for i in Lcomplexity_std if i[1]!=inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcomplexity_std_avg = avg_lists(Lcomplexity_std)\n",
    "plot_lists(Lcomplexity_std_avg,Lcomplexity_short_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-directive",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
